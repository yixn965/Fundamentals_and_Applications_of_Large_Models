{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 225,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013479359730412805,
      "grad_norm": 4.962264537811279,
      "learning_rate": 9.999512620046522e-05,
      "loss": 1.5104947090148926,
      "step": 1,
      "token_acc": 0.6647264260768335
    },
    {
      "epoch": 0.06739679865206402,
      "grad_norm": 0.7858035564422607,
      "learning_rate": 9.987820251299122e-05,
      "loss": 1.0281611680984497,
      "step": 5,
      "token_acc": 0.7070811744386873
    },
    {
      "epoch": 0.13479359730412804,
      "grad_norm": 0.6706020832061768,
      "learning_rate": 9.951340343707852e-05,
      "loss": 0.8153454780578613,
      "step": 10,
      "token_acc": 0.7226239669421488
    },
    {
      "epoch": 0.2021903959561921,
      "grad_norm": 0.4778897166252136,
      "learning_rate": 9.890738003669029e-05,
      "loss": 0.7703199863433838,
      "step": 15,
      "token_acc": 0.7377985462097612
    },
    {
      "epoch": 0.2695871946082561,
      "grad_norm": 0.7561716437339783,
      "learning_rate": 9.806308479691595e-05,
      "loss": 0.7191479206085205,
      "step": 20,
      "token_acc": 0.7617527568195008
    },
    {
      "epoch": 0.33698399326032014,
      "grad_norm": 0.7503404021263123,
      "learning_rate": 9.698463103929542e-05,
      "loss": 0.6588592052459716,
      "step": 25,
      "token_acc": 0.7665210267613326
    },
    {
      "epoch": 0.4043807919123842,
      "grad_norm": 0.9298023581504822,
      "learning_rate": 9.567727288213005e-05,
      "loss": 0.6257725715637207,
      "step": 30,
      "token_acc": 0.7690649420641337
    },
    {
      "epoch": 0.4717775905644482,
      "grad_norm": 0.7522068023681641,
      "learning_rate": 9.414737964294636e-05,
      "loss": 0.6223872184753418,
      "step": 35,
      "token_acc": 0.7821330902461258
    },
    {
      "epoch": 0.5391743892165122,
      "grad_norm": 0.6878897547721863,
      "learning_rate": 9.24024048078213e-05,
      "loss": 0.5910067081451416,
      "step": 40,
      "token_acc": 0.7787465940054495
    },
    {
      "epoch": 0.6065711878685762,
      "grad_norm": 0.8482911586761475,
      "learning_rate": 9.045084971874738e-05,
      "loss": 0.5951324462890625,
      "step": 45,
      "token_acc": 0.7810682178741407
    },
    {
      "epoch": 0.6739679865206403,
      "grad_norm": 1.0663113594055176,
      "learning_rate": 8.83022221559489e-05,
      "loss": 0.5641098976135254,
      "step": 50,
      "token_acc": 0.781718963165075
    },
    {
      "epoch": 0.7413647851727043,
      "grad_norm": 0.9921150207519531,
      "learning_rate": 8.596699001693255e-05,
      "loss": 0.5675565242767334,
      "step": 55,
      "token_acc": 0.7832241153342071
    },
    {
      "epoch": 0.8087615838247684,
      "grad_norm": 0.7154849171638489,
      "learning_rate": 8.345653031794292e-05,
      "loss": 0.5570620536804199,
      "step": 60,
      "token_acc": 0.7839068825910931
    },
    {
      "epoch": 0.8761583824768323,
      "grad_norm": 0.8982962369918823,
      "learning_rate": 8.07830737662829e-05,
      "loss": 0.5405517578125,
      "step": 65,
      "token_acc": 0.7898041185334003
    },
    {
      "epoch": 0.9435551811288964,
      "grad_norm": 1.1153357028961182,
      "learning_rate": 7.795964517353735e-05,
      "loss": 0.5909168243408203,
      "step": 70,
      "token_acc": 0.7803192756730999
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.8306471109390259,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.5753838539123535,
      "step": 75,
      "token_acc": 0.7859070464767616
    },
    {
      "epoch": 1.067396798652064,
      "grad_norm": 0.7763887047767639,
      "learning_rate": 7.191855733945387e-05,
      "loss": 0.5081229686737061,
      "step": 80,
      "token_acc": 0.80448533640023
    },
    {
      "epoch": 1.134793597304128,
      "grad_norm": 0.8776726126670837,
      "learning_rate": 6.873032967079561e-05,
      "loss": 0.5054690837860107,
      "step": 85,
      "token_acc": 0.8131241084165478
    },
    {
      "epoch": 1.2021903959561921,
      "grad_norm": 1.0119953155517578,
      "learning_rate": 6.545084971874738e-05,
      "loss": 0.4912278652191162,
      "step": 90,
      "token_acc": 0.805759457933371
    },
    {
      "epoch": 1.2695871946082562,
      "grad_norm": 1.116557002067566,
      "learning_rate": 6.209609477998338e-05,
      "loss": 0.49198312759399415,
      "step": 95,
      "token_acc": 0.8123962368566685
    },
    {
      "epoch": 1.3369839932603202,
      "grad_norm": 0.8274175524711609,
      "learning_rate": 5.868240888334653e-05,
      "loss": 0.49359378814697263,
      "step": 100,
      "token_acc": 0.8137384412153237
    },
    {
      "epoch": 1.4043807919123843,
      "grad_norm": 0.7868894338607788,
      "learning_rate": 5.522642316338268e-05,
      "loss": 0.502705430984497,
      "step": 105,
      "token_acc": 0.8042650418888042
    },
    {
      "epoch": 1.4717775905644481,
      "grad_norm": 0.8592790961265564,
      "learning_rate": 5.174497483512506e-05,
      "loss": 0.5236734390258789,
      "step": 110,
      "token_acc": 0.7937434827945777
    },
    {
      "epoch": 1.5391743892165122,
      "grad_norm": 1.025655746459961,
      "learning_rate": 4.825502516487497e-05,
      "loss": 0.4989504814147949,
      "step": 115,
      "token_acc": 0.8052014278429372
    },
    {
      "epoch": 1.6065711878685762,
      "grad_norm": 0.9897079467773438,
      "learning_rate": 4.477357683661734e-05,
      "loss": 0.49677605628967286,
      "step": 120,
      "token_acc": 0.8072096128170895
    },
    {
      "epoch": 1.6739679865206403,
      "grad_norm": 0.9735336303710938,
      "learning_rate": 4.131759111665349e-05,
      "loss": 0.5002683639526367,
      "step": 125,
      "token_acc": 0.8070818070818071
    },
    {
      "epoch": 1.7413647851727043,
      "grad_norm": 0.9259362816810608,
      "learning_rate": 3.790390522001662e-05,
      "loss": 0.4749647617340088,
      "step": 130,
      "token_acc": 0.8199577613516368
    },
    {
      "epoch": 1.8087615838247684,
      "grad_norm": 0.9671305418014526,
      "learning_rate": 3.4549150281252636e-05,
      "loss": 0.4777059555053711,
      "step": 135,
      "token_acc": 0.8131672597864769
    },
    {
      "epoch": 1.8761583824768322,
      "grad_norm": 1.1280057430267334,
      "learning_rate": 3.12696703292044e-05,
      "loss": 0.4818758964538574,
      "step": 140,
      "token_acc": 0.8152024235747728
    },
    {
      "epoch": 1.9435551811288962,
      "grad_norm": 0.9475682377815247,
      "learning_rate": 2.8081442660546125e-05,
      "loss": 0.492142915725708,
      "step": 145,
      "token_acc": 0.8139968068121342
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.261483907699585,
      "learning_rate": 2.500000000000001e-05,
      "loss": 0.49612650871276853,
      "step": 150,
      "token_acc": 0.8196884322174346
    },
    {
      "epoch": 2.067396798652064,
      "grad_norm": 0.9568262100219727,
      "learning_rate": 2.2040354826462668e-05,
      "loss": 0.4559802532196045,
      "step": 155,
      "token_acc": 0.8169952051145445
    },
    {
      "epoch": 2.134793597304128,
      "grad_norm": 0.927592396736145,
      "learning_rate": 1.9216926233717085e-05,
      "loss": 0.4744154453277588,
      "step": 160,
      "token_acc": 0.824678800856531
    },
    {
      "epoch": 2.202190395956192,
      "grad_norm": 0.7231791019439697,
      "learning_rate": 1.6543469682057106e-05,
      "loss": 0.45995001792907714,
      "step": 165,
      "token_acc": 0.8230042016806722
    },
    {
      "epoch": 2.269587194608256,
      "grad_norm": 1.0368247032165527,
      "learning_rate": 1.4033009983067452e-05,
      "loss": 0.4778395175933838,
      "step": 170,
      "token_acc": 0.8117816091954023
    },
    {
      "epoch": 2.3369839932603202,
      "grad_norm": 0.6485165953636169,
      "learning_rate": 1.1697777844051105e-05,
      "loss": 0.45786170959472655,
      "step": 175,
      "token_acc": 0.8267590618336887
    },
    {
      "epoch": 2.4043807919123843,
      "grad_norm": 0.8460174202919006,
      "learning_rate": 9.549150281252633e-06,
      "loss": 0.4501026630401611,
      "step": 180,
      "token_acc": 0.8320174244486795
    },
    {
      "epoch": 2.4717775905644483,
      "grad_norm": 0.7899780869483948,
      "learning_rate": 7.597595192178702e-06,
      "loss": 0.4732694149017334,
      "step": 185,
      "token_acc": 0.8239938869077942
    },
    {
      "epoch": 2.5391743892165124,
      "grad_norm": 0.7919395565986633,
      "learning_rate": 5.852620357053651e-06,
      "loss": 0.44511971473693845,
      "step": 190,
      "token_acc": 0.8294593888743798
    },
    {
      "epoch": 2.6065711878685764,
      "grad_norm": 0.9464884400367737,
      "learning_rate": 4.322727117869951e-06,
      "loss": 0.4623297691345215,
      "step": 195,
      "token_acc": 0.8226737474024475
    },
    {
      "epoch": 2.6739679865206405,
      "grad_norm": 1.097703456878662,
      "learning_rate": 3.0153689607045845e-06,
      "loss": 0.44778966903686523,
      "step": 200,
      "token_acc": 0.8300970873786407
    },
    {
      "epoch": 2.7413647851727045,
      "grad_norm": 1.1338622570037842,
      "learning_rate": 1.9369152030840556e-06,
      "loss": 0.4168081760406494,
      "step": 205,
      "token_acc": 0.8425423187480038
    },
    {
      "epoch": 2.8087615838247686,
      "grad_norm": 0.7722930908203125,
      "learning_rate": 1.0926199633097157e-06,
      "loss": 0.449352502822876,
      "step": 210,
      "token_acc": 0.8250720461095101
    },
    {
      "epoch": 2.876158382476832,
      "grad_norm": 0.8954272270202637,
      "learning_rate": 4.865965629214819e-07,
      "loss": 0.48466739654541013,
      "step": 215,
      "token_acc": 0.8134257047300526
    },
    {
      "epoch": 2.9435551811288962,
      "grad_norm": 1.3063483238220215,
      "learning_rate": 1.2179748700879012e-07,
      "loss": 0.47316803932189944,
      "step": 220,
      "token_acc": 0.818487830139824
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.7425652742385864,
      "learning_rate": 0.0,
      "loss": 0.40578770637512207,
      "step": 225,
      "token_acc": 0.828421052631579
    }
  ],
  "logging_steps": 5,
  "max_steps": 225,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.4653216018219e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
