{"loss": 1.51049471, "grad_norm": 4.96226454, "learning_rate": 0.0001, "token_acc": 0.66472643, "epoch": 0.01347936, "global_step/max_steps": "1/225", "percentage": "0.44%", "elapsed_time": "12s", "remaining_time": "46m 57s", "memory(GiB)": 16.86, "train_speed(iter/s)": 0.079493}
{"loss": 1.02816117, "grad_norm": 0.78580356, "learning_rate": 9.988e-05, "token_acc": 0.70708117, "epoch": 0.0673968, "global_step/max_steps": "5/225", "percentage": "2.22%", "elapsed_time": "56s", "remaining_time": "41m 13s", "memory(GiB)": 21.02, "train_speed(iter/s)": 0.088936}
{"loss": 0.81534548, "grad_norm": 0.67060208, "learning_rate": 9.951e-05, "token_acc": 0.72262397, "epoch": 0.1347936, "global_step/max_steps": "10/225", "percentage": "4.44%", "elapsed_time": "1m 48s", "remaining_time": "38m 52s", "memory(GiB)": 21.02, "train_speed(iter/s)": 0.092162}
{"loss": 0.77031999, "grad_norm": 0.47788972, "learning_rate": 9.891e-05, "token_acc": 0.73779855, "epoch": 0.2021904, "global_step/max_steps": "15/225", "percentage": "6.67%", "elapsed_time": "2m 42s", "remaining_time": "37m 57s", "memory(GiB)": 21.02, "train_speed(iter/s)": 0.092192}
{"loss": 0.71914792, "grad_norm": 0.75617164, "learning_rate": 9.806e-05, "token_acc": 0.76175276, "epoch": 0.26958719, "global_step/max_steps": "20/225", "percentage": "8.89%", "elapsed_time": "3m 36s", "remaining_time": "37m 0s", "memory(GiB)": 21.02, "train_speed(iter/s)": 0.092314}
{"loss": 0.65885921, "grad_norm": 0.7503404, "learning_rate": 9.698e-05, "token_acc": 0.76652103, "epoch": 0.33698399, "global_step/max_steps": "25/225", "percentage": "11.11%", "elapsed_time": "4m 29s", "remaining_time": "35m 57s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.092696}
{"loss": 0.62577257, "grad_norm": 0.92980236, "learning_rate": 9.568e-05, "token_acc": 0.76906494, "epoch": 0.40438079, "global_step/max_steps": "30/225", "percentage": "13.33%", "elapsed_time": "5m 21s", "remaining_time": "34m 47s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.093403}
{"loss": 0.62238722, "grad_norm": 0.7522068, "learning_rate": 9.415e-05, "token_acc": 0.78213309, "epoch": 0.47177759, "global_step/max_steps": "35/225", "percentage": "15.56%", "elapsed_time": "6m 15s", "remaining_time": "34m 0s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.093105}
{"loss": 0.59100671, "grad_norm": 0.68788975, "learning_rate": 9.24e-05, "token_acc": 0.77874659, "epoch": 0.53917439, "global_step/max_steps": "40/225", "percentage": "17.78%", "elapsed_time": "7m 10s", "remaining_time": "33m 10s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.092933}
{"loss": 0.59513245, "grad_norm": 0.84829116, "learning_rate": 9.045e-05, "token_acc": 0.78106822, "epoch": 0.60657119, "global_step/max_steps": "45/225", "percentage": "20.00%", "elapsed_time": "8m 4s", "remaining_time": "32m 18s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.092832}
{"loss": 0.5641099, "grad_norm": 1.06631136, "learning_rate": 8.83e-05, "token_acc": 0.78171896, "epoch": 0.67396799, "global_step/max_steps": "50/225", "percentage": "22.22%", "elapsed_time": "8m 57s", "remaining_time": "31m 22s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.09295}
{"loss": 0.56755652, "grad_norm": 0.99211502, "learning_rate": 8.597e-05, "token_acc": 0.78322412, "epoch": 0.74136479, "global_step/max_steps": "55/225", "percentage": "24.44%", "elapsed_time": "9m 50s", "remaining_time": "30m 25s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.093124}
{"loss": 0.55706205, "grad_norm": 0.71548492, "learning_rate": 8.346e-05, "token_acc": 0.78390688, "epoch": 0.80876158, "global_step/max_steps": "60/225", "percentage": "26.67%", "elapsed_time": "10m 43s", "remaining_time": "29m 30s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.093201}
{"loss": 0.54055176, "grad_norm": 0.89829624, "learning_rate": 8.078e-05, "token_acc": 0.78980412, "epoch": 0.87615838, "global_step/max_steps": "65/225", "percentage": "28.89%", "elapsed_time": "11m 36s", "remaining_time": "28m 34s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.093304}
{"loss": 0.59091682, "grad_norm": 1.1153357, "learning_rate": 7.796e-05, "token_acc": 0.78031928, "epoch": 0.94355518, "global_step/max_steps": "70/225", "percentage": "31.11%", "elapsed_time": "12m 30s", "remaining_time": "27m 40s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.093323}
{"loss": 0.57538385, "grad_norm": 1.83064711, "learning_rate": 7.5e-05, "token_acc": 0.78590705, "epoch": 1.0, "global_step/max_steps": "75/225", "percentage": "33.33%", "elapsed_time": "13m 12s", "remaining_time": "26m 24s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.094692}
{"loss": 0.50812297, "grad_norm": 0.7763887, "learning_rate": 7.192e-05, "token_acc": 0.80448534, "epoch": 1.0673968, "global_step/max_steps": "80/225", "percentage": "35.56%", "elapsed_time": "14m 6s", "remaining_time": "25m 33s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.094527}
{"loss": 0.50546908, "grad_norm": 0.87767261, "learning_rate": 6.873e-05, "token_acc": 0.81312411, "epoch": 1.1347936, "global_step/max_steps": "85/225", "percentage": "37.78%", "elapsed_time": "14m 58s", "remaining_time": "24m 39s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.094653}
{"loss": 0.49122787, "grad_norm": 1.01199532, "learning_rate": 6.545e-05, "token_acc": 0.80575946, "epoch": 1.2021904, "global_step/max_steps": "90/225", "percentage": "40.00%", "elapsed_time": "15m 48s", "remaining_time": "23m 42s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.094906}
{"loss": 0.49198313, "grad_norm": 1.116557, "learning_rate": 6.21e-05, "token_acc": 0.81239624, "epoch": 1.26958719, "global_step/max_steps": "95/225", "percentage": "42.22%", "elapsed_time": "16m 39s", "remaining_time": "22m 48s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.095019}
{"loss": 0.49359379, "grad_norm": 0.82741755, "learning_rate": 5.868e-05, "token_acc": 0.81373844, "epoch": 1.33698399, "global_step/max_steps": "100/225", "percentage": "44.44%", "elapsed_time": "17m 31s", "remaining_time": "21m 54s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.09509}
{"loss": 0.50270543, "grad_norm": 0.78688943, "learning_rate": 5.523e-05, "token_acc": 0.80426504, "epoch": 1.40438079, "global_step/max_steps": "105/225", "percentage": "46.67%", "elapsed_time": "18m 23s", "remaining_time": "21m 0s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.095193}
{"loss": 0.52367344, "grad_norm": 0.8592791, "learning_rate": 5.174e-05, "token_acc": 0.79374348, "epoch": 1.47177759, "global_step/max_steps": "110/225", "percentage": "48.89%", "elapsed_time": "19m 14s", "remaining_time": "20m 7s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.095249}
{"loss": 0.49895048, "grad_norm": 1.02565575, "learning_rate": 4.826e-05, "token_acc": 0.80520143, "epoch": 1.53917439, "global_step/max_steps": "115/225", "percentage": "51.11%", "elapsed_time": "20m 6s", "remaining_time": "19m 14s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.095314}
{"loss": 0.49677606, "grad_norm": 0.98970795, "learning_rate": 4.477e-05, "token_acc": 0.80720961, "epoch": 1.60657119, "global_step/max_steps": "120/225", "percentage": "53.33%", "elapsed_time": "20m 56s", "remaining_time": "18m 19s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.095484}
{"loss": 0.50026836, "grad_norm": 0.97353363, "learning_rate": 4.132e-05, "token_acc": 0.80708181, "epoch": 1.67396799, "global_step/max_steps": "125/225", "percentage": "55.56%", "elapsed_time": "21m 49s", "remaining_time": "17m 27s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.095472}
{"loss": 0.47496476, "grad_norm": 0.92593628, "learning_rate": 3.79e-05, "token_acc": 0.81995776, "epoch": 1.74136479, "global_step/max_steps": "130/225", "percentage": "57.78%", "elapsed_time": "22m 40s", "remaining_time": "16m 34s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.09552}
{"loss": 0.47770596, "grad_norm": 0.96713054, "learning_rate": 3.455e-05, "token_acc": 0.81316726, "epoch": 1.80876158, "global_step/max_steps": "135/225", "percentage": "60.00%", "elapsed_time": "23m 32s", "remaining_time": "15m 41s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.095587}
{"loss": 0.4818759, "grad_norm": 1.12800574, "learning_rate": 3.127e-05, "token_acc": 0.81520242, "epoch": 1.87615838, "global_step/max_steps": "140/225", "percentage": "62.22%", "elapsed_time": "24m 22s", "remaining_time": "14m 47s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.095732}
{"loss": 0.49214292, "grad_norm": 0.94756824, "learning_rate": 2.808e-05, "token_acc": 0.81399681, "epoch": 1.94355518, "global_step/max_steps": "145/225", "percentage": "64.44%", "elapsed_time": "25m 13s", "remaining_time": "13m 55s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.095795}
{"loss": 0.49612651, "grad_norm": 1.26148391, "learning_rate": 2.5e-05, "token_acc": 0.81968843, "epoch": 2.0, "global_step/max_steps": "150/225", "percentage": "66.67%", "elapsed_time": "25m 57s", "remaining_time": "12m 58s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.096289}
{"loss": 0.45598025, "grad_norm": 0.95682621, "learning_rate": 2.204e-05, "token_acc": 0.81699521, "epoch": 2.0673968, "global_step/max_steps": "155/225", "percentage": "68.89%", "elapsed_time": "26m 51s", "remaining_time": "12m 7s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.09617}
{"loss": 0.47441545, "grad_norm": 0.9275924, "learning_rate": 1.922e-05, "token_acc": 0.8246788, "epoch": 2.1347936, "global_step/max_steps": "160/225", "percentage": "71.11%", "elapsed_time": "27m 42s", "remaining_time": "11m 15s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.096266}
{"loss": 0.45995002, "grad_norm": 0.7231791, "learning_rate": 1.654e-05, "token_acc": 0.8230042, "epoch": 2.2021904, "global_step/max_steps": "165/225", "percentage": "73.33%", "elapsed_time": "28m 34s", "remaining_time": "10m 23s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.096241}
{"loss": 0.47783952, "grad_norm": 1.0368247, "learning_rate": 1.403e-05, "token_acc": 0.81178161, "epoch": 2.26958719, "global_step/max_steps": "170/225", "percentage": "75.56%", "elapsed_time": "29m 24s", "remaining_time": "9m 30s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.096366}
{"loss": 0.45786171, "grad_norm": 0.6485166, "learning_rate": 1.17e-05, "token_acc": 0.82675906, "epoch": 2.33698399, "global_step/max_steps": "175/225", "percentage": "77.78%", "elapsed_time": "30m 17s", "remaining_time": "8m 39s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.096267}
{"loss": 0.45010266, "grad_norm": 0.84601742, "learning_rate": 9.55e-06, "token_acc": 0.83201742, "epoch": 2.40438079, "global_step/max_steps": "180/225", "percentage": "80.00%", "elapsed_time": "31m 12s", "remaining_time": "7m 48s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.096128}
{"loss": 0.47326941, "grad_norm": 0.78997809, "learning_rate": 7.6e-06, "token_acc": 0.82399389, "epoch": 2.47177759, "global_step/max_steps": "185/225", "percentage": "82.22%", "elapsed_time": "32m 1s", "remaining_time": "6m 55s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.096274}
{"loss": 0.44511971, "grad_norm": 0.79193956, "learning_rate": 5.85e-06, "token_acc": 0.82945939, "epoch": 2.53917439, "global_step/max_steps": "190/225", "percentage": "84.44%", "elapsed_time": "32m 55s", "remaining_time": "6m 3s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.096174}
{"loss": 0.46232977, "grad_norm": 0.94648844, "learning_rate": 4.32e-06, "token_acc": 0.82267375, "epoch": 2.60657119, "global_step/max_steps": "195/225", "percentage": "86.67%", "elapsed_time": "33m 47s", "remaining_time": "5m 11s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.096163}
{"loss": 0.44778967, "grad_norm": 1.09770346, "learning_rate": 3.02e-06, "token_acc": 0.83009709, "epoch": 2.67396799, "global_step/max_steps": "200/225", "percentage": "88.89%", "elapsed_time": "34m 38s", "remaining_time": "4m 19s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.096243}
{"loss": 0.41680818, "grad_norm": 1.13386226, "learning_rate": 1.94e-06, "token_acc": 0.84254232, "epoch": 2.74136479, "global_step/max_steps": "205/225", "percentage": "91.11%", "elapsed_time": "35m 28s", "remaining_time": "3m 27s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.096319}
{"loss": 0.4493525, "grad_norm": 0.77229309, "learning_rate": 1.09e-06, "token_acc": 0.82507205, "epoch": 2.80876158, "global_step/max_steps": "210/225", "percentage": "93.33%", "elapsed_time": "36m 18s", "remaining_time": "2m 35s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.096375}
{"loss": 0.4846674, "grad_norm": 0.89542723, "learning_rate": 4.9e-07, "token_acc": 0.8134257, "epoch": 2.87615838, "global_step/max_steps": "215/225", "percentage": "95.56%", "elapsed_time": "37m 9s", "remaining_time": "1m 43s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.096437}
{"loss": 0.47316804, "grad_norm": 1.30634832, "learning_rate": 1.2e-07, "token_acc": 0.81848783, "epoch": 2.94355518, "global_step/max_steps": "220/225", "percentage": "97.78%", "elapsed_time": "38m 0s", "remaining_time": "51s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.096465}
{"loss": 0.40578771, "grad_norm": 1.74256527, "learning_rate": 0.0, "token_acc": 0.82842105, "epoch": 3.0, "global_step/max_steps": "225/225", "percentage": "100.00%", "elapsed_time": "38m 42s", "remaining_time": "0s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.09689}
{"train_runtime": 2322.5362, "train_samples_per_second": 1.533, "train_steps_per_second": 0.097, "total_flos": 7.4653216018219e+16, "train_loss": 0.53751575, "epoch": 3.0, "global_step/max_steps": "225/225", "percentage": "100.00%", "elapsed_time": "38m 42s", "remaining_time": "0s", "memory(GiB)": 22.42, "train_speed(iter/s)": 0.096877}
{"model_parameter_info": "PeftModelForCausalLM: 2136.2483M Params (8.7163M Trainable [0.4080%]), 0.0001M Buffers.", "last_model_checkpoint": "/opt/data/private/gaoj/GaoJing/curriculum/Fundamentals_and_Applications_of_Large_Models/Model_Finetune/dataset/output/v1-20251218-214530/checkpoint-225", "best_model_checkpoint": null, "best_metric": null, "global_step": 225, "log_history": [{"loss": 1.5104947090148926, "grad_norm": 4.962264537811279, "learning_rate": 9.999512620046522e-05, "token_acc": 0.6647264260768335, "epoch": 0.013479359730412805, "step": 1}, {"loss": 1.0281611680984497, "grad_norm": 0.7858035564422607, "learning_rate": 9.987820251299122e-05, "token_acc": 0.7070811744386873, "epoch": 0.06739679865206402, "step": 5}, {"loss": 0.8153454780578613, "grad_norm": 0.6706020832061768, "learning_rate": 9.951340343707852e-05, "token_acc": 0.7226239669421488, "epoch": 0.13479359730412804, "step": 10}, {"loss": 0.7703199863433838, "grad_norm": 0.4778897166252136, "learning_rate": 9.890738003669029e-05, "token_acc": 0.7377985462097612, "epoch": 0.2021903959561921, "step": 15}, {"loss": 0.7191479206085205, "grad_norm": 0.7561716437339783, "learning_rate": 9.806308479691595e-05, "token_acc": 0.7617527568195008, "epoch": 0.2695871946082561, "step": 20}, {"loss": 0.6588592052459716, "grad_norm": 0.7503404021263123, "learning_rate": 9.698463103929542e-05, "token_acc": 0.7665210267613326, "epoch": 0.33698399326032014, "step": 25}, {"loss": 0.6257725715637207, "grad_norm": 0.9298023581504822, "learning_rate": 9.567727288213005e-05, "token_acc": 0.7690649420641337, "epoch": 0.4043807919123842, "step": 30}, {"loss": 0.6223872184753418, "grad_norm": 0.7522068023681641, "learning_rate": 9.414737964294636e-05, "token_acc": 0.7821330902461258, "epoch": 0.4717775905644482, "step": 35}, {"loss": 0.5910067081451416, "grad_norm": 0.6878897547721863, "learning_rate": 9.24024048078213e-05, "token_acc": 0.7787465940054495, "epoch": 0.5391743892165122, "step": 40}, {"loss": 0.5951324462890625, "grad_norm": 0.8482911586761475, "learning_rate": 9.045084971874738e-05, "token_acc": 0.7810682178741407, "epoch": 0.6065711878685762, "step": 45}, {"loss": 0.5641098976135254, "grad_norm": 1.0663113594055176, "learning_rate": 8.83022221559489e-05, "token_acc": 0.781718963165075, "epoch": 0.6739679865206403, "step": 50}, {"loss": 0.5675565242767334, "grad_norm": 0.9921150207519531, "learning_rate": 8.596699001693255e-05, "token_acc": 0.7832241153342071, "epoch": 0.7413647851727043, "step": 55}, {"loss": 0.5570620536804199, "grad_norm": 0.7154849171638489, "learning_rate": 8.345653031794292e-05, "token_acc": 0.7839068825910931, "epoch": 0.8087615838247684, "step": 60}, {"loss": 0.5405517578125, "grad_norm": 0.8982962369918823, "learning_rate": 8.07830737662829e-05, "token_acc": 0.7898041185334003, "epoch": 0.8761583824768323, "step": 65}, {"loss": 0.5909168243408203, "grad_norm": 1.1153357028961182, "learning_rate": 7.795964517353735e-05, "token_acc": 0.7803192756730999, "epoch": 0.9435551811288964, "step": 70}, {"loss": 0.5753838539123535, "grad_norm": 1.8306471109390259, "learning_rate": 7.500000000000001e-05, "token_acc": 0.7859070464767616, "epoch": 1.0, "step": 75}, {"loss": 0.5081229686737061, "grad_norm": 0.7763887047767639, "learning_rate": 7.191855733945387e-05, "token_acc": 0.80448533640023, "epoch": 1.067396798652064, "step": 80}, {"loss": 0.5054690837860107, "grad_norm": 0.8776726126670837, "learning_rate": 6.873032967079561e-05, "token_acc": 0.8131241084165478, "epoch": 1.134793597304128, "step": 85}, {"loss": 0.4912278652191162, "grad_norm": 1.0119953155517578, "learning_rate": 6.545084971874738e-05, "token_acc": 0.805759457933371, "epoch": 1.2021903959561921, "step": 90}, {"loss": 0.49198312759399415, "grad_norm": 1.116557002067566, "learning_rate": 6.209609477998338e-05, "token_acc": 0.8123962368566685, "epoch": 1.2695871946082562, "step": 95}, {"loss": 0.49359378814697263, "grad_norm": 0.8274175524711609, "learning_rate": 5.868240888334653e-05, "token_acc": 0.8137384412153237, "epoch": 1.3369839932603202, "step": 100}, {"loss": 0.502705430984497, "grad_norm": 0.7868894338607788, "learning_rate": 5.522642316338268e-05, "token_acc": 0.8042650418888042, "epoch": 1.4043807919123843, "step": 105}, {"loss": 0.5236734390258789, "grad_norm": 0.8592790961265564, "learning_rate": 5.174497483512506e-05, "token_acc": 0.7937434827945777, "epoch": 1.4717775905644481, "step": 110}, {"loss": 0.4989504814147949, "grad_norm": 1.025655746459961, "learning_rate": 4.825502516487497e-05, "token_acc": 0.8052014278429372, "epoch": 1.5391743892165122, "step": 115}, {"loss": 0.49677605628967286, "grad_norm": 0.9897079467773438, "learning_rate": 4.477357683661734e-05, "token_acc": 0.8072096128170895, "epoch": 1.6065711878685762, "step": 120}, {"loss": 0.5002683639526367, "grad_norm": 0.9735336303710938, "learning_rate": 4.131759111665349e-05, "token_acc": 0.8070818070818071, "epoch": 1.6739679865206403, "step": 125}, {"loss": 0.4749647617340088, "grad_norm": 0.9259362816810608, "learning_rate": 3.790390522001662e-05, "token_acc": 0.8199577613516368, "epoch": 1.7413647851727043, "step": 130}, {"loss": 0.4777059555053711, "grad_norm": 0.9671305418014526, "learning_rate": 3.4549150281252636e-05, "token_acc": 0.8131672597864769, "epoch": 1.8087615838247684, "step": 135}, {"loss": 0.4818758964538574, "grad_norm": 1.1280057430267334, "learning_rate": 3.12696703292044e-05, "token_acc": 0.8152024235747728, "epoch": 1.8761583824768322, "step": 140}, {"loss": 0.492142915725708, "grad_norm": 0.9475682377815247, "learning_rate": 2.8081442660546125e-05, "token_acc": 0.8139968068121342, "epoch": 1.9435551811288962, "step": 145}, {"loss": 0.49612650871276853, "grad_norm": 1.261483907699585, "learning_rate": 2.500000000000001e-05, "token_acc": 0.8196884322174346, "epoch": 2.0, "step": 150}, {"loss": 0.4559802532196045, "grad_norm": 0.9568262100219727, "learning_rate": 2.2040354826462668e-05, "token_acc": 0.8169952051145445, "epoch": 2.067396798652064, "step": 155}, {"loss": 0.4744154453277588, "grad_norm": 0.927592396736145, "learning_rate": 1.9216926233717085e-05, "token_acc": 0.824678800856531, "epoch": 2.134793597304128, "step": 160}, {"loss": 0.45995001792907714, "grad_norm": 0.7231791019439697, "learning_rate": 1.6543469682057106e-05, "token_acc": 0.8230042016806722, "epoch": 2.202190395956192, "step": 165}, {"loss": 0.4778395175933838, "grad_norm": 1.0368247032165527, "learning_rate": 1.4033009983067452e-05, "token_acc": 0.8117816091954023, "epoch": 2.269587194608256, "step": 170}, {"loss": 0.45786170959472655, "grad_norm": 0.6485165953636169, "learning_rate": 1.1697777844051105e-05, "token_acc": 0.8267590618336887, "epoch": 2.3369839932603202, "step": 175}, {"loss": 0.4501026630401611, "grad_norm": 0.8460174202919006, "learning_rate": 9.549150281252633e-06, "token_acc": 0.8320174244486795, "epoch": 2.4043807919123843, "step": 180}, {"loss": 0.4732694149017334, "grad_norm": 0.7899780869483948, "learning_rate": 7.597595192178702e-06, "token_acc": 0.8239938869077942, "epoch": 2.4717775905644483, "step": 185}, {"loss": 0.44511971473693845, "grad_norm": 0.7919395565986633, "learning_rate": 5.852620357053651e-06, "token_acc": 0.8294593888743798, "epoch": 2.5391743892165124, "step": 190}, {"loss": 0.4623297691345215, "grad_norm": 0.9464884400367737, "learning_rate": 4.322727117869951e-06, "token_acc": 0.8226737474024475, "epoch": 2.6065711878685764, "step": 195}, {"loss": 0.44778966903686523, "grad_norm": 1.097703456878662, "learning_rate": 3.0153689607045845e-06, "token_acc": 0.8300970873786407, "epoch": 2.6739679865206405, "step": 200}, {"loss": 0.4168081760406494, "grad_norm": 1.1338622570037842, "learning_rate": 1.9369152030840556e-06, "token_acc": 0.8425423187480038, "epoch": 2.7413647851727045, "step": 205}, {"loss": 0.449352502822876, "grad_norm": 0.7722930908203125, "learning_rate": 1.0926199633097157e-06, "token_acc": 0.8250720461095101, "epoch": 2.8087615838247686, "step": 210}, {"loss": 0.48466739654541013, "grad_norm": 0.8954272270202637, "learning_rate": 4.865965629214819e-07, "token_acc": 0.8134257047300526, "epoch": 2.876158382476832, "step": 215}, {"loss": 0.47316803932189944, "grad_norm": 1.3063483238220215, "learning_rate": 1.2179748700879012e-07, "token_acc": 0.818487830139824, "epoch": 2.9435551811288962, "step": 220}, {"loss": 0.40578770637512207, "grad_norm": 1.7425652742385864, "learning_rate": 0.0, "token_acc": 0.828421052631579, "epoch": 3.0, "step": 225}, {"train_runtime": 2322.5362, "train_samples_per_second": 1.533, "train_steps_per_second": 0.097, "total_flos": 7.4653216018219e+16, "train_loss": 0.537515754699707, "epoch": 3.0, "step": 225}], "memory": 22.421875}
